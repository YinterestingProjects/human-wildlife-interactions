{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce9905a-18ef-4ec1-993d-6a6528ccc070",
   "metadata": {},
   "source": [
    "# This notebook finds and extracts all of the Wildlife videos from the overall YT8M dataset and then stores their video and frame data separately for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23770ce1-2a8e-469b-80db-767a72b68eab",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b3bef3-3371-436e-a7bc-c9b2479a1942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 15:03:57.498334: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-03-31 15:03:58.672147: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-03-31 15:03:58.673766: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 15:04:06.779365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4aa4def-5e14-49f1-9fb0-87be7a5df51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "1.3.4\n",
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(pd.__version__)\n",
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a56ccc-a47d-4739-9c21-bcd420c72794",
   "metadata": {},
   "source": [
    "### Set the base path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e4706-0e65-46c7-808c-d25c8da3f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be the path where you are storing the entire YT8M dataset\n",
    "base_path = Path('/nfs/turbo/seas-nhcarter/human_wildlife_interactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9db5d1b-fdfd-41cd-8043-253034d1c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and make sure we can access the correct directory\n",
    "video_path = Path(base_path / 'video')\n",
    "frame_path = Path(base_path / 'frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3627ca-a3bf-4be6-ba22-1c07691d3537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wildlife(01280g): 4243 videos found\n"
     ]
    }
   ],
   "source": [
    "# find the specific wildlife video ids we know we want\n",
    "# get list of ids from yt8m api\n",
    "def get_entity_videoIds(entity_name):\n",
    "    ''' gets a list of video ids in the YT8M training dataset tagged with a given entity(name)'''\n",
    "\n",
    "    entity_id = entity2id[entity_name]\n",
    "\n",
    "    url = f'https://storage.googleapis.com/data.yt8m.org/2/j/v/{entity_id}.js'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status() \n",
    "\n",
    "    data = response.text\n",
    "    pattern = r'\\w+'\n",
    "    ids = re.findall(pattern, data)[2:] # video ids start at index 2 onward\n",
    "    print(f'{entity_name}({entity_id}): {len(ids)} videos found')\n",
    "\n",
    "    return ids\n",
    "\n",
    "new_url = 'https://research.google.com/youtube8m/csv/2/vocabulary.csv'\n",
    "new_vocab = pd.read_csv(new_url)\n",
    "animal_df = new_vocab[(new_vocab.Vertical1 == 'Pets & Animals') | (new_vocab.Vertical2 == 'Pets & Animals')] # Pets & Animal only present in V1&2\n",
    "summary_df = animal_df.groupby(['Name','KnowledgeGraphId']).agg({'TrainVideoCount':'sum'}).reset_index()\n",
    "entity2id = dict(zip(summary_df.Name, summary_df.KnowledgeGraphId.str[3:]))\n",
    "videoIds = get_entity_videoIds('Wildlife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d223d88-bbda-41cd-b2a1-77994c396def",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = os.listdir(video_path / 'train')\n",
    "frame_list = os.listdir(frame_path / 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "291bc4f9-38cb-40d7-9703-8fad477f5357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3845 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_2175184/245029194.py:8: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2247/3845 [03:03<01:45, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in /nfs/turbo/seas-nhcarter/human_wildlife_interactions/video/train/2_video_train_download_plan.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3845/3845 [05:06<00:00, 12.55it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "\n",
    "# iterate through all TFRecords\n",
    "for record in tqdm(video_list):\n",
    "    path = video_path / 'train' / record\n",
    "    # iterate through all videos in the record and add to dictionary if it is in the wildlife category\n",
    "    try:\n",
    "        for video in tf.compat.v1.python_io.tf_record_iterator(path):\n",
    "            seq_video = tf.train.Example.FromString(video)\n",
    "            video_id = seq_video.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8')\n",
    "            if video_id in videoIds:\n",
    "                if video_id not in data_dict.keys():\n",
    "                    data_dict[video_id] = {'video': video, 'video_example': seq_video}\n",
    "    except:\n",
    "        print(\"Error in {}\".format(path))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44bc2521-3297-4d02-8990-bb0081715881",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = base_path / 'classifier_video_data/video_data.pkl'\n",
    "pickle.dump(data_dict, open(base_path / write_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d4bf7c6-d17f-4c59-b26e-ea40efde8a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3845/3845 [2:31:59<00:00,  2.37s/it]  \n"
     ]
    }
   ],
   "source": [
    "frame_dict = {}\n",
    "# iterate through all TFRecords\n",
    "for record in tqdm(frame_list):\n",
    "    path = frame_path / 'train' / record\n",
    "    # iterate through all videos in the record and add to dictionary if it is in the wildlife category\n",
    "    try:\n",
    "        for frame in tf.compat.v1.python_io.tf_record_iterator(path):\n",
    "            seq_frame = tf.train.Example.FromString(frame)\n",
    "            seq_example = tf.train.SequenceExample.FromString(frame)\n",
    "            frame_id = seq_frame.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8')\n",
    "            if frame_id in videoIds:\n",
    "                if frame_id not in frame_dict.keys():\n",
    "                    frame_dict[frame_id] = {'frame':frame,'frame_example':seq_frame,'sequence_example':seq_example}\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b47702-d04f-48a8-96bf-9fb52ca4eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = base_path /'classifier_video_data/frame_data.pkl'\n",
    "pickle.dump(frame_dict, open(write_path, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
