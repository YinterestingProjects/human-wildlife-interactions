### A general note for all notebooks in this repository: The notebooks were all created in either Colab or on the Great Lakes computing cluster. In both cases data was stored in such a way that relative paths were not feasible. Therefore you will generally need to set some path variables to where the data is stored and where the repository is cloned, then the code will generate the rest of the paths from there. Please look for the comments telling you where to set those paths to avoid any issues.

### Generating the Data - 
There are two methods you can use to get all of the data necessary for the follow on topic modeling / descriptive analysis / classification components.
For the user more comfortable with command line options, please reference the Step by Step instructions. For those who want things to be automated but with fewer
options, please see the 1 notebook version.

#### Data Generation (Step by Step):
1) Start with the API_crawl.ipynb notebook. Run the entire file. (make sure you specify the correct path for your API keys)
2) Run the combine.py file located in src/data.
   - This will generate a dataframe
3) Run the translation.py file located in src/features and specify the title column.
4) Run the translation.py file located in src/features once more and this time specify the description.
5) You can remove the intermediate file created if you so desire.
6) Run 2_wildlifeVideoExtraction.ipynb

#### Data Generation (Somewhat Automated):
1) Open the file 1_dataExtractionPipeline.ipynb
2) Follow the instructions at the top to specify the 5 necessary pieces of information.
3) Run the entire file. The outputs will now be located in a new directory as per the instructions.
4) Run 2_wildlifeVideoExtraction.ipynb

Regardless of which option you chose earlier you will need to do the following steps:

#### Topic Modeling:
1) Once the translation step has been accomplished run BERTopics.ipynb
2) You will need to do some manual analysis of the results in BERTopics_evaluation.ipynb
   - This will generate the hunting_dict.json
3) (OPTIONAL) You can choose to run LDA.ipynb if you want to compare the results with BERTopics.

#### Classifier Data Generation:
Complete this step only after hunting_dict.json has been generated by the topic modeling section.
1) Run 3a_GetFrameData.ipynb
2) Run 3b_CreateVideoMatrices.ipynb

#### Once these have been completed (it will take a while with fresh data FYI), you can proceed to the reports folder.
