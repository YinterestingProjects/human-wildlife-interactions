Generating the Data - 
There are two methods you can use to get all of the data necessary for the follow on topic modeling / descriptive analysis / classification components.
For the user more comfortable with command line options, please reference the Step by Step instructions. For those who want things to be automated but with fewer
options, please see the 1 notebook version.

Data Generation (Step by Step):
1) Start with the API_crawl.ipynb notebook. Run the entire file. (make sure you specify the correct path for your API keys)
2) Run the combine.py file located in src/data.
   - This will generate a dataframe
3) Run the translation.py file located in src/features and specify the title column.
4) Run the translation.py file located in src/features once more and this time specify the description.
5) You can remove the intermediate file created if you so desire.
6) Run 2_wildlifeVideoExtraction.ipynb

Data Generation (Somewhat Automated):
1) Open the file 1_dataExtractionPipeline.ipynb
2) Follow the instructions at the top to specify the 5 necessary pieces of information.
3) Run the entire file. The outputs will now be located in a new directory as per the instructions.
4) Run 2_wildlifeVideoExtraction.ipynb

Regardless of which option you chose earlier you will need to do the following steps:

Topic Modeling:
1) Once the translation step has been accomplished run BERTopics.ipynb
2) You will need to do some manual analysis of the results in BERTopics_evaluation.ipynb
3) SALLY: what order do things need to happen here?

Classifier Data Generation:
Complete this step only after hunter_dict.json has been generated by the topic modeling section.
1) Run 3a_GetFrameData.ipynb
2) Run 3b_CreateVideoMatrices.ipynb

------------------------ Not Required ------------------------------
EDA:
The EDA notebooks are provided as a starting point for anyone who wants to explore the various elements of the data / API interfaces. 
No special instructions are necessary, although you may need to setup the correct paths for data storage and API keys.
