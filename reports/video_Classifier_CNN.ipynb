{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a28888e-b6df-4d82-a123-7870f1ec0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/supriya-gdptl/kaggle-youtube8m/blob/master/video_level_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498651d-f52d-4745-aa3f-79547162e10a",
   "metadata": {},
   "source": [
    "This notebook serves to test the CNN architecture and see how resolving class imbalance through resampling fares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d3207-f9bc-4c32-893d-e611fb89b149",
   "metadata": {},
   "source": [
    "### Imports / Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5753f635-c415-47db-bc1d-3f6188d3c6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 13:03:19.366867: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-17 13:03:19.408123: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-17 13:03:19.414009: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 13:03:20.528519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from path import Path\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea73861-fa70-4b7a-9010-c4f243368c35",
   "metadata": {},
   "source": [
    "You will need to set the base path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2207d19a-5d25-47ae-a122-c3caa75baa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the base path\n",
    "base_path = Path('/nfs/turbo/seas-nhcarter/human_wildlife_interactions/classifier_video_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65154d1a-0d19-4bfd-8086-154404763575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the matrices\n",
    "train_path = Path(base_path / \"train_mat.csv\")\n",
    "test_path = Path(base_path / \"test_mat.csv\")\n",
    "val_path = Path(base_path / \"val_mat.csv\")\n",
    "train_df = pd.read_csv(train_path) \n",
    "test_df = pd.read_csv(test_path)\n",
    "val_df = pd.read_csv(val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59812cf-4ee0-4098-a486-945b4084c75c",
   "metadata": {},
   "source": [
    "### Network Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b53f98-204c-415a-8779-2c8e20b41a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple matmul CNN approach with class weights based off of Supriya Gadi Patil's CNN implementation\n",
    "# https://github.com/supriya-gdptl/kaggle-youtube8m\n",
    "l2_reg = .00000001\n",
    "# define inputs\n",
    "input_1 = keras.Input(shape=(1024,))\n",
    "input_2 = keras.Input(shape=(128,))\n",
    "\n",
    "# reduce using fully connected layer\n",
    "videoNN = keras.layers.Dense(32, activation=tf.nn.leaky_relu,kernel_regularizer=keras.regularizers.l2(l2_reg))(input_1)\n",
    "audioNN = keras.layers.Dense(32, activation=tf.nn.leaky_relu,kernel_regularizer=keras.regularizers.l2(l2_reg))(input_2)\n",
    "\n",
    "# adjust shape to make everything (32x1) instead of (32,)\n",
    "video_dim = tf.expand_dims(videoNN, -1)\n",
    "audio_dim = tf.expand_dims(audioNN, -1)\n",
    "\n",
    "# transpose audio to enable matmul operation\n",
    "audio_dim = tf.transpose(audio_dim, perm=[0,2,1])\n",
    "\n",
    "# matmul to produce 32x32 result\n",
    "matrix = tf.matmul(video_dim, audio_dim)\n",
    "\n",
    "# need another empty dimension for CNN to work\n",
    "matrix = tf.expand_dims(matrix, -1)\n",
    "\n",
    "# 2 layer CNN with single pooling layer\n",
    "convolution_1 = keras.layers.Conv2D(filters=8, kernel_size=[3,3])(matrix)\n",
    "average_pool = keras.layers.AveragePooling2D(pool_size=2, strides=2)(convolution_1)\n",
    "convolution_2 = keras.layers.Conv2D(filters=4, kernel_size=[3,3])(average_pool)\n",
    "\n",
    "# flatten output layer\n",
    "flattening = keras.layers.Flatten()(convolution_2)\n",
    "\n",
    "# output layer\n",
    "output = keras.layers.Dense(1, activation=tf.nn.sigmoid, kernel_regularizer=keras.regularizers.l2(l2_reg))(flattening)\n",
    "\n",
    "# build the graph\n",
    "cnn_model = keras.Model(inputs=[input_1,input_2], outputs=[output])\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.AUC()])\n",
    "initial_weights = cnn_model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411dcce-0a51-4ba0-b6c5-77b56be240b4",
   "metadata": {},
   "source": [
    "### Fit the model - normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385e1b2c-44cc-495e-950b-6de1e8ff9448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v = train_df.iloc[:,:-1]\n",
    "y_train_v = train_df.iloc[:,-1]\n",
    "X_val_v = val_df.iloc[:,:-1]\n",
    "y_val_v = val_df.iloc[:,-1]\n",
    "X_test_v = test_df.iloc[:,:-1]\n",
    "y_test_v = test_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d948f616-2caf-47b7-b282-affc191d4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video = X_train_v.iloc[:, :1024]\n",
    "train_audio = X_train_v.iloc[:,1024:-1]\n",
    "test_video = X_test_v.iloc[:, :1024]\n",
    "test_audio = X_test_v.iloc[:, 1024:-1]\n",
    "val_video = X_val_v.iloc[:, :1024]\n",
    "val_audio = X_val_v.iloc[:, 1024:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "159afddc-47bc-4561-9a11-ecd02a704ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 15ms/step - loss: 0.2518 - auc: 0.5004 - val_loss: 0.7469 - val_auc: 0.6168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b7f47c3c40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(x=[train_video, train_audio], y=y_train_v, class_weight={0: .1, 1: .9},validation_data=([val_video, val_audio], y_val_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f56bafa6-e171-456a-8055-408e3d503dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7553 - auc: 0.5898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7552503943443298, 0.5898419618606567]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(x=[test_video, test_audio], y=np.array(y_test_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "168a60c9-c524-4f97-8c59-ac701bb4ae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = cnn_model.predict(x=[test_video, test_audio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6574d5d5-e723-448c-9ec4-45005be1dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the probabilities into actual predictions\n",
    "preds_translated = []\n",
    "for pred in preds:\n",
    "    preds_translated.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b64d3d5b-6075-4a65-9de3-336372c25862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.91566265, 0.        ]),\n",
       " array([1., 0.]),\n",
       " array([0.95597484, 0.        ]),\n",
       " array([532,  49]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the score information\n",
    "precision_recall_fscore_support(y_test_v, preds_translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebba40a2-56f6-4224-9e52-155143df4780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the roc / auc score\n",
    "roc_auc_score(y_test_v, preds_translated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d58534-cbb6-4682-bc2b-35f973ac8171",
   "metadata": {},
   "source": [
    "### \"Balance\" the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afcbd707-2184-48d7-a217-b51e690c1050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2559, 1154)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resample the imbalanced class\n",
    "train_df = train_df.rename(columns= {'1152':\"y\"})\n",
    "hunting_df = train_df.loc[train_df.y == 1.0]\n",
    "non_hunting_df = train_df.loc[train_df.y != 1.0]\n",
    "hunting_upsampled = resample(hunting_df, n_samples = len(non_hunting_df))\n",
    "hunting_upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "841f692c-9de7-4f6e-b4ed-f7662a5f8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the dataframes\n",
    "new_train_df = pd.concat([non_hunting_df, hunting_upsampled])\n",
    "# shuffle the dataframe\n",
    "new_train_df = new_train_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "734e75f4-0009-4df4-a4be-dbc92d672d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the new model\n",
    "balanced_cnn = tf.keras.Model(inputs=[input_1,input_2], outputs=[output])\n",
    "balanced_cnn.set_weights(initial_weights)\n",
    "balanced_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a76aa8e-b6a1-435d-943d-60247ee83b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 3s 13ms/step - loss: 0.3314 - accuracy: 0.5225 - val_loss: 1.2182 - val_accuracy: 0.1053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b7dd4a0250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_video = new_train_df.iloc[:,:1024]\n",
    "X_train_audio = new_train_df.iloc[:, 1025:-1]\n",
    "X_train_y = new_train_df.y\n",
    "balanced_cnn.fit(x=[X_train_video, X_train_audio], y=X_train_y ,class_weight={0: 0.1, 1: 0.9}, validation_data=([val_video, val_audio], np.array(y_val_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac2a0210-c48d-4302-8187-2d98eeb8aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step - loss: 1.2423 - auc: 0.5673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.242297887802124, 0.5673431158065796]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(x=[test_video, test_audio], y=np.array(y_test_v).reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85a0b3dc-49ea-4f05-b369-655c65984d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.91566265, 0.        ]),\n",
       " array([1., 0.]),\n",
       " array([0.95597484, 0.        ]),\n",
       " array([532,  49]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = cnn_model.predict(x=[test_video, test_audio])\n",
    "# turn the probabilities into actual predictions\n",
    "preds_translated = []\n",
    "for pred in preds:\n",
    "    preds_translated.append(np.argmax(pred))\n",
    "# get the score information\n",
    "precision_recall_fscore_support(y_test_v, preds_translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f596a3fe-9ba7-4852-8242-c79ab63eb080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the roc / auc score\n",
    "roc_auc_score(y_test_v, preds_translated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
