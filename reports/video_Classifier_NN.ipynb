{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afe1ce62-7525-4629-ac55-67f9e95882ca",
   "metadata": {},
   "source": [
    "This notebook serves to test the Fully Connected architecture and see how resolving class imbalance through resampling fares.\n",
    "This approach is inspired by the multimodal video input fully connected neural network approach found here: https://github.com/rchavezj/Label_YT_Videos/blob/master/code/Algorithms.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e2ccd23-fe3d-40c3-b71e-84edfebf4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "import json\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from path import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26965bf6-0a10-475d-b031-e78afd1bf353",
   "metadata": {},
   "source": [
    "You will need to set the base path here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ff6b88-e958-4d63-9ce2-455f0a512211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the base path\n",
    "base_path = Path('/nfs/turbo/seas-nhcarter/human_wildlife_interactions/classifier_video_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bc9403-4a79-465b-8842-f608e4984e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the matrices\n",
    "train_path = Path(base_path / \"train_mat.csv\")\n",
    "test_path = Path(base_path / \"test_mat.csv\")\n",
    "val_path = Path(base_path / \"val_mat.csv\")\n",
    "train_df = pd.read_csv(train_path) \n",
    "test_df = pd.read_csv(test_path)\n",
    "val_df = pd.read_csv(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921d2751-417b-471b-8043-838e8a99882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model design based off of Roberto Chavez's paper\n",
    "# https://github.com/rchavezj/Label_YT_Videos\n",
    "\n",
    "# audio input with fully connected layers\n",
    "audio_input = keras.Input(shape=(128,))\n",
    "audio_fc1 = keras.layers.Dense(512, activation='relu')(audio_input)\n",
    "audio_fc2 = keras.layers.Dense(1024, activation='relu')(audio_fc1)\n",
    "audio_fc3 = keras.layers.Dense(4096, activation='relu')(audio_fc2)\n",
    "audio_fc4 = keras.layers.Dense(8192, activation='relu')(audio_fc3)\n",
    "audio_fc5 = keras.layers.Dense(4096, activation='relu')(audio_fc4)\n",
    "# video input with fully connected layers\n",
    "video_input = keras.Input(shape=(1024,))\n",
    "video_fc1 = keras.layers.Dense(512, activation='relu')(video_input)\n",
    "video_fc2 = keras.layers.Dense(1024, activation='relu')(video_fc1)\n",
    "video_fc3 = keras.layers.Dense(4096, activation='relu')(video_fc2)\n",
    "video_fc4 = keras.layers.Dense(8192, activation='relu')(video_fc3)\n",
    "video_fc5 = keras.layers.Dense(4096, activation='relu')(video_fc4)\n",
    "# merge data and pass to fully connected layer\n",
    "nn_merge = keras.layers.concatenate([audio_fc5, video_fc5])\n",
    "nn_fc = keras.layers.Dense(4096, activation='relu')(nn_merge) \n",
    "# output layer\n",
    "nn_output = keras.layers.Dense(1, activation=tf.nn.sigmoid,name='nn_output')(nn_fc)\n",
    "# compile model\n",
    "nn_model = keras.Model(inputs=[audio_input, video_input],outputs=[nn_output])\n",
    "nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.AUC()])\n",
    "# grab the initial weights to reset the model between parameter changes\n",
    "nn_weights = nn_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce7e426-992b-4c22-8747-28e21a006efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep the data\n",
    "X_train_v = train_df.iloc[:,:-1]\n",
    "y_train_v = train_df.iloc[:,-1]\n",
    "X_val_v = val_df.iloc[:,:-1]\n",
    "y_val_v = val_df.iloc[:,-1]\n",
    "X_test_v = test_df.iloc[:,:-1]\n",
    "y_test_v = test_df.iloc[:,-1]\n",
    "train_video = X_train_v.iloc[:, :1024]\n",
    "train_audio = X_train_v.iloc[:,1024:-1]\n",
    "test_video = X_test_v.iloc[:, :1024]\n",
    "test_audio = X_test_v.iloc[:, 1024:-1]\n",
    "val_video = X_val_v.iloc[:, :1024]\n",
    "val_audio = X_val_v.iloc[:, 1024:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf9935c-2fb0-49ff-a004-1651d2d06126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 446s 5s/step - loss: 4.0281 - auc_1: 0.4992 - val_loss: 0.6342 - val_auc_1: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152021799460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "nn_model.fit(x=[train_audio, train_video], y=np.array(y_train_v).reshape((-1,1)),class_weight={0:.1, 1:.9},\n",
    "             validation_data=([val_audio,val_video], np.array(y_val_v).reshape((-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1241352-a833-4f87-a511-dea8b0547a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 4s 221ms/step - loss: 0.6391 - auc_1: 0.5848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6391013860702515, 0.5847590565681458]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.evaluate(x=[test_audio, test_video], y=np.array(y_test_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdddb5d-1034-480e-a0f2-d84e66d52ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 4s 219ms/step\n"
     ]
    }
   ],
   "source": [
    "raw_preds = nn_model.predict([test_audio, test_video])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110e3c44-3520-4126-808b-b41153e6d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for pair in raw_preds:\n",
    "    preds.append(np.argmax(pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f377637-3928-4849-87fe-36744fef3edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 49)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_count = 0\n",
    "correct_count = 0\n",
    "for idx, val in enumerate(preds):\n",
    "    if val == 1:\n",
    "        pred_count += 1\n",
    "    if y_test_v[idx] == 1:\n",
    "        correct_count += 1\n",
    "pred_count, correct_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a85b6708-dbd2-441a-b94b-8b3b7cc21286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.91566265, 0.        ]),\n",
       " array([1., 0.]),\n",
       " array([0.95597484, 0.        ]),\n",
       " array([532,  49]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test_v, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20c78f86-7ca6-4ac1-a2de-aa2dada857be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_v, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c26ce71e-a80a-42bb-a91d-70d9aaf3904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns= {'1152':\"y\"})\n",
    "\n",
    "hunting_df = train_df.loc[train_df.y == 1.0]\n",
    "non_hunting_df = train_df.loc[train_df.y != 1.0]\n",
    "\n",
    "hunting_upsampled = resample(hunting_df, n_samples = len(non_hunting_df))\n",
    "\n",
    "new_train_df = pd.concat([non_hunting_df, hunting_upsampled])\n",
    "# shuffle the dataframe\n",
    "new_train_df = new_train_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f097973-8196-46cf-b494-aa565ddbcd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_nn = keras.Model(inputs=[audio_input, video_input],outputs=[nn_output])\n",
    "balanced_nn.set_weights(nn_weights)\n",
    "balanced_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82effb08-8a19-4fbc-9275-b38b58f4c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_video = new_train_df.iloc[:,:1024]\n",
    "X_train_audio = new_train_df.iloc[:, 1025:-1]\n",
    "X_train_y = new_train_df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dafcc1b1-7d0d-4e23-9179-7126f8b3cc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 431s 5s/step - loss: 12.1539 - auc_2: 0.5153 - val_loss: 0.3118 - val_auc_2: 0.5907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15201f964640>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_nn.fit(x=[train_audio, train_video], y=np.array(y_train_v),validation_data=([val_audio,val_video], np.array(y_val_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa642526-fcdf-4bd9-8010-843809954c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 4s 208ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 49)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_preds2 = nn_model.predict([test_audio, test_video])\n",
    "preds2 = []\n",
    "for pair in raw_preds2:\n",
    "    preds2.append(np.argmax(pair))\n",
    "    \n",
    "pred_count2 = 0\n",
    "correct_count2 = 0\n",
    "for idx, val in enumerate(preds2):\n",
    "    if val == 1:\n",
    "        pred_count2 += 1\n",
    "    if y_test_v[idx] == 1:\n",
    "        correct_count2 += 1\n",
    "pred_count2, correct_count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fdf9356-a1db-4cad-87a6-574aa464a831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.91566265, 0.        ]),\n",
       " array([1., 0.]),\n",
       " array([0.95597484, 0.        ]),\n",
       " array([532,  49]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test_v, preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95274e35-fc4e-4967-912a-e7ee7de34645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_v, preds2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
